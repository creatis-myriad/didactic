# @package _global_

defaults:
  - cardiac-multimodal-representation
  - /callbacks:
      - transformer_encoder_freeze
  - override /task/model/encoder: cardinal-ft-transformer

trainer:
  max_steps: 500

task:
  predict_losses:
    ht_severity:
      _target_: torch.nn.CrossEntropyLoss
  ordinal_mode: True
  contrastive_loss:
    _target_: vital.metrics.train.metric.NTXent
  contrastive_loss_weight: 0

callbacks:
  transformer_encoder_freeze:
    finetune_layers: null
  learning_rate_finder:
    _target_: pytorch_lightning.callbacks.LearningRateFinder

# Change checkpoint loading defaults to:
ckpt: ??? # Make it mandatory to provide a checkpoint
weights_only: True  # Only load the weights and ignore the hyperparameters
strict: False # Only load weights where they match the defined network, to only some changes (e.g. heads, etc.)
